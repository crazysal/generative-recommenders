# ===========================
# ML-1M GCNBaseline Config
# ===========================

# Dataset
train_fn.dataset_name = "ml-1m"
train_fn.max_sequence_length = 200
train_fn.local_batch_size = 84

# Model architecture
train_fn.main_module = "GCNBaseline"
train_fn.item_embedding_dim = 50
train_fn.dropout_rate = 0.2  # For input features or global dropout (optional)

# GCN-specific encoder config (mapped in model constructor)
gcn_encoder.hidden_dim = 256         # Used in first GCN layer
gcn_encoder.dropout_rate = 0.1       # Applied after ReLU

# Pooling strategy
gcn_encoder.pooling = "last"                     # Options: last, mean, sum

# Training
train_fn.num_epochs = 101
train_fn.learning_rate = 1e-3
train_fn.weight_decay = 0
train_fn.num_warmup_steps = 0
train_fn.enable_tf32 = True

# Embedding modules
train_fn.user_embedding_norm = "l2_norm"
train_fn.item_l2_norm = True
train_fn.l2_norm_eps = 1e-6

# Loss and sampling
train_fn.loss_module = "SampledSoftmaxLoss"
train_fn.num_negatives = 128
train_fn.sampling_strategy = "local"
train_fn.temperature = 0.05

# Similarity / interaction head
train_fn.interaction_module_type = "DotProduct"

# Evaluation method
train_fn.top_k_method = "MIPSBruteForceTopK"

# DataLoader
create_data_loader.prefetch_factor = 128
create_data_loader.num_workers = 8
